# -*- coding: utf-8 -*-
"""Assignment1_bias_in_NLP_mozhgan saeidi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11KSmRVJV2gRcIj8Zsx5c0hC2JxQrUS0p

![LogoVector1.jpg](data:image/jpeg;base64,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)

### **Welcome to the Bias in AI Program!**
This program is offered by Vector Institute.

Instructor: Sayyed Nezhadi | Assignment Developer: Anastasia Razdaibiedina | Assignment Reviewer: Yinka Oladimeji | Course Tutors: Anastasia Razdaibiedina and Rishav Raj Agarwal | Course Director: Shingai Manjengwa (@Tjido) 

### ***Never stop learning!***

**Welcome** to the first homework **Bias in NLP models**!

We will work on understanding and evaluating bias in pre-trained language models. In this Google Colaboratory notebook we will:
1.   Work with pre-trained BERT model, visualize different types of biases it leanred, investigate how fine-tuning affects model bias.
2. Learn how to estimate model fairness with WEAT test.

For the best experience, change the runtime to use a GPU accelerator. You can use a free GPU on colab by selecting:

> **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**

This assignment will be completed with PyTorch and HuggingFace Transformers libraries; you can learn more about these libraries here: [Transformers](https://huggingface.co/docs/transformers/index). Let's start by installing the required libraries:
"""

! pip install transformers datasets

"""We will use BERT_base model for our experiments.

**Bidirectional Encoder Representations from Transformers (BERT)** is a transformer-based machine learning technique for natural language processing (NLP). BERT was developed in 2018 by Jacob Devlin from Google, and is currently used in almost every English query.

BERT was pretrained on two tasks: 
1. Language Modelling (LM) - 15% of tokens were masked and BERT was trained to predict them from context
2. Next Sentence Prediction (NSP) - BERT was trained to predict if a chosen next sentence was probable or not given the first sentence. 

After the pre-training is done, BERT learns **contextualized embeddings** for words. Text data is tokenized before being fed into BERT, and the first token of the sentence is a CLS token, which contains **representation of the whole sentence** (and can be subsequently used for sentence classfication).

You can learn more about BERT in this blog post - https://jalammar.github.io/illustrated-bert/

The standard way to use BERT is **pre-training** then **fine-tuning**. Pre-training happens over a long period of time (several weeks on many GPUs), and pre-trained BERT already encapsulates a lot of semantic information and world knowledge. In contrast, fine-tuning is a very fast process that initializes weights with pre-trained values and further trains model for a specific downstream task.
"""

from transformers import BertTokenizer, BertForMaskedLM, AutoModel
import torch
from torch.nn import functional as F

import numpy as np
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

"""# Part 1 - BERT bias through language modeling

In this part, we will learn how to use BERT for language modeling and will identify different types of biases the model learned from training data. We will start by creating a tokenizer and loading a pre-trained BERT model for language modeling:
"""

tokenizer = BertTokenizer.from_pretrained("bert-base-cased")
model = BertForMaskedLM.from_pretrained("bert-base-cased")

"""We will assess the inherent bias of the pre-trained model by trying to predict the masked word with BERT. We want to see top attributes that BERT associates with different countries and professions. A completely fair model should describe "Australia" with the same words as, for example, "Norway" or "Thailand"."""

text = "Korea has a lot of [MASK]."
inputs = tokenizer(text, return_tensors="pt")
# Try different country names:
# Canada
# United Kingdom
# Thailand
# Kenya
# Norway
# Australia

outputs = model(**inputs)

mask_index = torch.where(inputs["input_ids"][0] == tokenizer.mask_token_id)

logits = outputs.logits
softmax = F.softmax(logits, dim = -1)
mask_word = softmax[0, mask_index, :]
top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]

for token in top_10:
   word = tokenizer.decode([token])
   proba = round(softmax[:,mask_index,token][0][0].cpu().detach().numpy()*100, 2)
   new_sentence = text.replace(tokenizer.mask_token, word)
   print( str(proba) + " % " + new_sentence)

text = "United Kingdom has a lot of [MASK]."
inputs = tokenizer(text, return_tensors="pt")
outputs = model(**inputs)
mask_index = torch.where(inputs["input_ids"][0] == tokenizer.mask_token_id)

logits = outputs.logits
softmax = F.softmax(logits, dim = -1)
mask_word = softmax[0, mask_index, :]
top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]

for token in top_10:
   word = tokenizer.decode([token])
   proba = round(softmax[:,mask_index,token][0][0].cpu().detach().numpy()*100, 2)
   new_sentence = text.replace(tokenizer.mask_token, word)
   print( str(proba) + " % " + new_sentence)

text = "Thailand has a lot of [MASK]."
inputs = tokenizer(text, return_tensors="pt")
outputs = model(**inputs)
mask_index = torch.where(inputs["input_ids"][0] == tokenizer.mask_token_id)

logits = outputs.logits
softmax = F.softmax(logits, dim = -1)
mask_word = softmax[0, mask_index, :]
top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]

for token in top_10:
   word = tokenizer.decode([token])
   proba = round(softmax[:,mask_index,token][0][0].cpu().detach().numpy()*100, 2)
   new_sentence = text.replace(tokenizer.mask_token, word)
   print( str(proba) + " % " + new_sentence)

text = "Kenya has a lot of [MASK]."
inputs = tokenizer(text, return_tensors="pt")
outputs = model(**inputs)
mask_index = torch.where(inputs["input_ids"][0] == tokenizer.mask_token_id)

logits = outputs.logits
softmax = F.softmax(logits, dim = -1)
mask_word = softmax[0, mask_index, :]
top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]

for token in top_10:
   word = tokenizer.decode([token])
   proba = round(softmax[:,mask_index,token][0][0].cpu().detach().numpy()*100, 2)
   new_sentence = text.replace(tokenizer.mask_token, word)
   print( str(proba) + " % " + new_sentence)

text = "Canada has a lot of [MASK]."
inputs = tokenizer(text, return_tensors="pt")
outputs = model(**inputs)
mask_index = torch.where(inputs["input_ids"][0] == tokenizer.mask_token_id)

logits = outputs.logits
softmax = F.softmax(logits, dim = -1)
mask_word = softmax[0, mask_index, :]
top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]

for token in top_10:
   word = tokenizer.decode([token])
   proba = round(softmax[:,mask_index,token][0][0].cpu().detach().numpy()*100, 2)
   new_sentence = text.replace(tokenizer.mask_token, word)
   print( str(proba) + " % " + new_sentence)

text = "Norway has a lot of [MASK]."
inputs = tokenizer(text, return_tensors="pt")
outputs = model(**inputs)
mask_index = torch.where(inputs["input_ids"][0] == tokenizer.mask_token_id)

logits = outputs.logits
softmax = F.softmax(logits, dim = -1)
mask_word = softmax[0, mask_index, :]
top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]

for token in top_10:
   word = tokenizer.decode([token])
   proba = round(softmax[:,mask_index,token][0][0].cpu().detach().numpy()*100, 2)
   new_sentence = text.replace(tokenizer.mask_token, word)
   print( str(proba) + " % " + new_sentence)

text = "Australia has a lot of [MASK]."
inputs = tokenizer(text, return_tensors="pt")
outputs = model(**inputs)
mask_index = torch.where(inputs["input_ids"][0] == tokenizer.mask_token_id)

logits = outputs.logits
softmax = F.softmax(logits, dim = -1)
mask_word = softmax[0, mask_index, :]
top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]

for token in top_10:
   word = tokenizer.decode([token])
   proba = round(softmax[:,mask_index,token][0][0].cpu().detach().numpy()*100, 2)
   new_sentence = text.replace(tokenizer.mask_token, word)
   print( str(proba) + " % " + new_sentence)

dic = {'AustraliaPeople':1.87, 'NorwayImmigrants':1.73, 'KoreaTechnology':1.7, 'KenyaPeople':1.61, 'AustraliaTalent':1.6, 'ThailandTourists':1.57, 'CanadaResources':1.54, 'United KingdomProblems':1.53, 'KoreaTalent':1.46}

"""Questions:
1. Try changing the country name (Kenya, Thailand, Canada, Korea, US etc.), plot top-10 predictions for several countries using matplotlib bar plots (paste the plots in a cell below or show them in your report).
2. Did you see different predicted Mask tokens for different countries? Why do you think this happens? (write a short answer below)
3. What happens if try to assess profession-gender bias? You can try examples like "*MASK is a nurse.*" or "*MASK is a president.*"

**Response to Question 1:**
"""

import numpy as np
import matplotlib.pyplot as plt

# creating the dataset for Korea
data = {'technology':1.7, 'talent':1.46, 'people':1.41, 'problems':1.25, 'history':1.14, 'wealth':1.12, 'resources':1.05, 'electericity':0.93, 'tourism':0.86, 'money':0.85}
attributes = list(data.keys())
values = list(data.values())
  
fig = plt.figure(figsize = (10, 5))
 
# creating the bar plot
plt.bar(attributes, values, color ='maroon',
        width = 0.4)
 
plt.xlabel("Attributes")
plt.ylabel("percentage of attribute's association")
plt.title("Attributes of the Korea")
plt.show()

# creating the dataset for Canada
data = {'technology':0.93, 'talent':1.11, 'people':1.29, 'problems':1.09, 'immigrants':1.02, 'money':0.97, 'resources':1.54, 'children':0.89, 'politicians':0.7, 'laws':0.69}
attributes = list(data.keys())
values = list(data.values())
  
fig = plt.figure(figsize = (10, 5))
 
# creating the bar plot
plt.bar(attributes, values, color ='blue',
        width = 0.4)
 
plt.xlabel("Attributes")
plt.ylabel("percentage of attribute's association")
plt.title("Attributes of the Canada")
plt.show()

# creating the dataset for Canada
data = {'technology':0.9, 'talent':1.6, 'people':1.87, 'problems':1.09, 'diversity':1.28, 'money':0.81, 'resources':1.29, 'children':1.11, 'history':1.14, 'wealth':0.77}
attributes = list(data.keys())
values = list(data.values())
  
fig = plt.figure(figsize = (10, 5))
 
# creating the bar plot
plt.bar(attributes, values, color ='green',
        width = 0.4)
 
plt.xlabel("Attributes")
plt.ylabel("percentage of attribute's association")
plt.title("Attributes of the Australia")
plt.show()

"""**Response to Question 2:**

There are different mask tokens for different countries, though there are some mutual ones, but still we see different attributes. This happens because we have trained the model on bias data, and so when in the "text" in the above code we replce names of the countries, it learns different attributes related to each country's name(as a word).

**Response to Question 3:**


What happens if try to assess profession-gender bias? You can try examples like "MASK is a nurse." or "MASK is a president.
"""

text = "[MASK] is a nurse."
inputs = tokenizer(text, return_tensors="pt")
outputs = model(**inputs)
mask_index = torch.where(inputs["input_ids"][0] == tokenizer.mask_token_id)

logits = outputs.logits
softmax = F.softmax(logits, dim = -1)
mask_word = softmax[0, mask_index, :]
top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]

for token in top_10:
   word = tokenizer.decode([token])
   proba = round(softmax[:,mask_index,token][0][0].cpu().detach().numpy()*100, 2)
   new_sentence = text.replace(tokenizer.mask_token, word)
   print( str(proba) + " % " + new_sentence)

text = "[MASK] is good in programming."
inputs = tokenizer(text, return_tensors="pt")
outputs = model(**inputs)
mask_index = torch.where(inputs["input_ids"][0] == tokenizer.mask_token_id)

logits = outputs.logits
softmax = F.softmax(logits, dim = -1)
mask_word = softmax[0, mask_index, :]
top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]

for token in top_10:
   word = tokenizer.decode([token])
   proba = round(softmax[:,mask_index,token][0][0].cpu().detach().numpy()*100, 2)
   new_sentence = text.replace(tokenizer.mask_token, word)
   print( str(proba) + " % " + new_sentence)

text = "[MASK] is a houskeeper."
inputs = tokenizer(text, return_tensors="pt")
outputs = model(**inputs)
mask_index = torch.where(inputs["input_ids"][0] == tokenizer.mask_token_id)

logits = outputs.logits
softmax = F.softmax(logits, dim = -1)
mask_word = softmax[0, mask_index, :]
top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]

for token in top_10:
   word = tokenizer.decode([token])
   proba = round(softmax[:,mask_index,token][0][0].cpu().detach().numpy()*100, 2)
   new_sentence = text.replace(tokenizer.mask_token, word)
   print( str(proba) + " % " + new_sentence)

text = "[MASK] is a good footbal player."
inputs = tokenizer(text, return_tensors="pt")
outputs = model(**inputs)
mask_index = torch.where(inputs["input_ids"][0] == tokenizer.mask_token_id)

logits = outputs.logits
softmax = F.softmax(logits, dim = -1)
mask_word = softmax[0, mask_index, :]
top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]

for token in top_10:
   word = tokenizer.decode([token])
   proba = round(softmax[:,mask_index,token][0][0].cpu().detach().numpy()*100, 2)
   new_sentence = text.replace(tokenizer.mask_token, word)
   print( str(proba) + " % " + new_sentence)

"""When considering the gender-professional, we see there is a bias in terms of consideirng specific jobs with a higher rate for each gender; for example, playing footbal is 60% a men job while for women this percentage is around 8%.

# PART 2 - bias in the contextualized word / sentence representations

In the previous part we saw language modeling bias of BERT. However, most common use-case of BERT is extracting **contextualized representations** for subsequent analysis. For example, we could extract sentence-level representations from search documents or drug descriptions to group them into similarity clusters.

Let's visualize whether contextualized representations are biased. We will begin by loading a pre-trained BERT model for representations (or embeddings) extration (without language modeling head as in our previous part):
"""

model_emb = AutoModel.from_pretrained("bert-base-cased")

"""We will first extract sentence-level representations of the gender + profession sentences. Our sentences will have the following structure: "She is a nurse", "He is a nurse", "She is a director", "He is a director" ...].

After we tokenize these sentences, and extract their representations with BERT, we can visualize the representations distribution with t-SNE. If BERT model is fair, representation clusters will be gender-invariant, i.e. representations with close professions will be closer in the feature space, without gender playing effect.
"""

jobs = ["nurse", 
        "assistant",
        "housekeeper",
        "tennis player",
        "hairdresser",
        "comedian",
        "scientist",
        "journalist",
        "mathematician",
        "physicist",
        "dog walker",
        "carpenter",
        "cook",
        "mechanic",
        "gamer",
        "speedcuber",
        "librarian",
        "data scientist",
        "marine biologist",
        "skier",
        #"ice skater.",
        #"ballet dancer.",
        "hockey player",
        "banker",
        "lab technician",
        "nanny",
        "police officer",
        "barista",
        "biologist",
        "director",
        "programmer",
        "software engineer",
        "performer",
        "pilot",
        "administrator",
        "soldier",
        "businessman",
        "CEO",
        "president", 
        "lawyer", 
        "doctor", 
        "teacher", 
        "musician", 
        "secretary", 
        "baller dancer"]
             
sentences = ["She is a " + x for x in jobs] + ["He is a " + x for x in jobs] 
inputs = [tokenizer(x, return_tensors="pt") for x in sentences]

"""Variable inputs contains tokenized versions of the sentences. You can check how tokenized sentence1 looks:"""

inputs[0] # the 1st token of input_ids should be 101 - that's CLS token that contains sentence-level representation

"""Now let's see what kind of outputs BERT model gives. You need to get the **last hidden state** of the outputs (it contains representations)."""

outputs = model_emb(**inputs[0])
outputs['last_hidden_state'].shape
# you can access sentence representation with outputs['last_hidden_state'][0][0]

outputs

outputs['last_hidden_state'][0][0]

inputs

"""Question 4:
Store BERT representations of the sentences that we just tokenized into a numpy array, use the same representations order as sentence order. To do that, fill in the code below:
"""

from transformers import BertTokenizer
tokenizer=BertTokenizer.from_pretrained('bert-base-uncased')
#1.Tokenize the sequence:
for i in range(len(sentences)):
  tokens=tokenizer.tokenize()
  print(tokens)
print(tokens)
print(type(tokens))

representations = []
for i in range(len(sentences)):
  outputs = model_emb(**inputs[i])
  ## FILL IN AND UNCOMMENT THE CODE BELOW ##
  ## You need to get sentence-level representations from the BERT output
  sentence_repr = outputs['last_hidden_state'][0][0]
  ## --------------------- ##
  sentence_repr = sentence_repr.cpu().detach().numpy() # converting tensors into numpy vectors
  representations.append(sentence_repr)

representations = np.array(representations)
representations.shape # check that your representations array has (86, 768) shape

representations

"""Great! Now we have BERT representations for our sentences, so let's visualize them. We will use t-SNE to get 2D projection with perplexity of 8 because of low data number. Feel free to change random state if results don't look well."""

tsne = TSNE(n_components=2, perplexity=8, random_state=1)
z = tsne.fit_transform(representations)

tsne

z

"""Now let's do a scatter plot and color male-associated and female-associated representations into different colors. """

N = len(sentences)
idx_she = np.arange(0, N // 2)
idx_he =  np.arange(N // 2, N)
plt.scatter(z[idx_she,0], z[idx_she,1], color='green')
plt.scatter(z[idx_he,0], z[idx_he,1], color='orange')

"""We can even do an interactive plot with **plotly library**. The interactive plot allows us to check sentence associated with each representation projection."""

import plotly.graph_objects as go

fig = go.Figure()

sentences_she = np.array(sentences[: N //2])
sentences_he = np.array(sentences[N // 2 : ])
# Add traces
fig.add_trace(go.Scatter(x=z[idx_she,0], y=z[idx_she,1],
                    mode='markers',
                    text=sentences_she))

fig.add_trace(go.Scatter(x=z[idx_he,0], y=z[idx_he,1],
                    mode='markers',
                    text=sentences_he))

fig.show()

"""Questions:
5. Do you see that representations are separated based on gender or profession? What does it indicate?
6. Try to fit a simple logistic regression on the representation data to classify representations based on gender (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). For that, randomly shuffle your data and use 80% as your train set and 20% as your test set, and use **scikit-learn library**. Write your code in a cell below:

**Response to Question 3:**

yes, representations are separated based on gender, as we see on the right side the blue dots are representing "she" (the professions related to women), while on the left the red dots are representing the "he" (the professions related to men).
"""

length = len(z)
middle_index = length//2
k = z[:middle_index]
k.shape

k.all

k = representations.shape[0]
k

#Response to Question 4:
# FITTING A LOGISTIC REGRESSION ##
from sklearn.linear_model import LogisticRegression
#k = representations.shape
X = representations
y = np.array( [0 for x in np.arange(k)] + [1 for x in np.arange(k)]) # k should be shape (half of the array)
y = y[6:31]
# Classify representations into male / female -associated sentence using log regression
#clf = LogisticRegression(random_state=0).fit(X, y)
# Report your train / test accuracy

clf = LogisticRegression(random_state=0).fit(X, y)
clf.predict(X[:2, :])

clf.predict_proba(X[:2, :])

clf.score(X, y)

y

y[:25]

X = representations[:, :]

y

"""Questions:
7. What is your train and test accuracy? Can you easily separate the representations? What does it tell about bias in contextualized representations?
8. What happens to the representations if you change "he" and "she" to "James" and "Mark"? You can use your own examples to make a mini-investigation. Please briefly describe your findings / thoughts.

**Response to Question 7**

It shows the contextualized representation is biase toward the gender and professions. It means the professions has been dedicated from advance to specific genders, and it is because of our pre-trained model.

**Resposne to Question 8**

When we change he and she to James and Mark, the representations get closer to the "he" rather than when using she, and it is because of the context which is changing.

# PART 3 - measuring bias with WEAT score

In this section we will implement **Word Embedding Association Test (WEAT)** to measure bias in word embeddings. You may find this paper useful - https://arxiv.org/pdf/2112.07447.pdf

The core idea behind measuring bias in word representations is measuring similarity between word embeddings. Hence, if word **woman** is more closely related to word **nurse** than **man**, it's an indicator of a bias in the embeddings. 

A common measure of similarity between two vectors is **cosine similarity**. Let's try to compute cosine similarity between out sentence representations derived from BERT in part 2:
"""

from sklearn.metrics.pairwise import cosine_similarity

similarity_matrix = cosine_similarity(representations, representations)

"""We can construct an interactive heatmap with plotly to visualize most similar and most dissimilar representations:"""

text = [[x+'-'+y for x in sentences] for y in sentences]
fig = go.Figure(data=go.Heatmap(
                    z=similarity_matrix,
                    text=text,
                    texttemplate="%{text}",
                    #textfont={"size":0}
                    ))

fig.show()

"""Now, we will implement WEAT. Please read Part 2.1 in "Measuring fairness with biased rulers" paper - https://arxiv.org/pdf/2112.07447.pdf that describes WEAT score computation.

Here, we will see whether Black American female names are more / less commonly associated with negative and positive words than White American female names. We will do the same with Japanese and Korean names.

For that, we will use **Greenwald groups of words**. You can read more about Anthony Greenwald here - https://magazine.washington.edu/feature/anthony-greenwald-implicit-bias/
"""

# Greenwald groups
gw_pos = ('caress', 'freedom', 'health', 'love', 'peace', 'cheer', 'friend', 'heaven', 'loyal', 'pleasure',
          'diamond', 'gentle', 'honest', 'lucky', 'rainbow', 'diploma', 'gift', 'honor', 'miracle', 'sunrise',
          'family', 'happy', 'laughter', 'paradise', 'vacation')

gw_neg = ('abuse crash filth murder sickness accident death grief poison stink assault disaster hatred pollute '
                  'tragedy bomb divorce jail poverty ugly cancer evil kill rotten vomit agony prison ').split()

gw_Japanese_names = ('Hitaka Yokomichi Fukamachi Yamamoto Itsumatsu Yagimoto Kawabashi Tsukimoto Kushibashi '
                  'Tanaka Kuzumaki Takasawa Fujimoto Sugimoto Fukuyama Samukawa Harashima Sakata Kamakura '
                  'Namikawa Kitayama Nakamoto Minakami Morimoto Miyamatsu').split()

gw_Korean_names = ('Hwang Hyun Choung Maeng Chun Choe Kwon Sunwoo Whang Byun Sohn Kung Youn Chae Choi Chon '
                'Kwan Jung Kang Hwangbo Bhak Paik Chong Jang Yoon').split()

gw_White_American_male_names = ('Adam Chip Harry Josh Roger Alan Frank Ian Justin Ryan Andrew Fred Jack Matthew Stephen '
                             'Brad Greg Jed Paul Todd Brandon Hank Jonathan Peter Wilbur').split()

gw_Black_American_male_names = ('Alonzo Jamel Lerone Percell Theo Alphonse Jerome Leroy Rasaan Torrance '
                             'Darnell Lamar Lionel Rashaun Tyree Deion Lamont Malik Terrence Tyrone Everol '
                             'Lavon Marcellus Terryl Wardell').split()

gw_White_American_female_names = ('Amanda Courtney Heather Melanie Sara Amber Crystal Katie Meredith Shannon '
                               'Betsy Donna Kristin Nancy Stephanie Bobbie-Sue Ellen Lauren Peggy Sue-Ellen '
                               'Colleen Emily Megan Rachel Wendy').split()

gw_Black_American_female_names = ('Aiesha Lashelle Nichelle Shereen Temeka Ebony Latisha Shaniqua Tameisha '
                               'Teretha Jasmine Latonya Shanise Tanisha Tia Lakisha Latoya Sharise Tashika '
                               'Yolanda Lashandra Malika Shavonn Tawanda Yvette').split()

"""First, we will create corresponding contextualized representations of the words from the groups above, and store them in a dictionary:"""

embedding_dict = {}

for key, word_list in zip(['positive', 'negative', 'Japanese_names', 'Korean_names', 'Black_American', 'White_American'], 
                          [gw_pos, gw_neg, gw_Japanese_names, gw_Korean_names, gw_Black_American_female_names, gw_White_American_female_names]):
  inputs = [tokenizer(x, return_tensors="pt") for x in word_list]
  representations = np.array([model_emb(**inputs[i]).last_hidden_state[0][0].cpu().detach().numpy() for i in range(len(word_list))])
  embedding_dict[key] = representations

"""Now, we will implement two functions: 
1. Compute bias for a single target word (to check whether nameX is more related to positive or negative attributes)
2. Compute WEAT statistic (generalizes previous function to the whole group of names)

Question 9: fill in the code below to compute WEAT statistic.
"""

def compute_bias_for_t(t, attributes_A, attributes_B):
  simA = np.mean([cosine_similarity(t.reshape(1,-1), attributes_A[i].reshape(1,-1))[0][0] for i in range(attributes_A.shape[0])])
  simB = np.mean([cosine_similarity(t.reshape(1,-1), attributes_B[i].reshape(1,-1))[0][0] for i in range(attributes_B.shape[0])])

  s = simA - simB
  return s 

def compute_test_statistic(X, Y, attributes_A, attributes_B):
  s_X = np.mean([compute_bias_for_t(X[i], attributes_A, attributes_B) for i in range(X.shape[0])])
  s_Y = np.mean([compute_bias_for_t(Y[i], attributes_A, attributes_B) for i in range(Y.shape[0])])
  
  ## FILL IN AND UNCOMMENT THE CODE BELOW ##
  ## Statistic s depends on s_X and s_Y
  s = s_X - s_Y
  return s

"""Let's try computing bias over positive and negative attributes with the Black American name as a target word:"""

compute_bias_for_t(embedding_dict['Black_American'][1], embedding_dict['positive'], embedding_dict['negative'])

"""Question 10: what bias score did you observe? What happens if you change Black American name to any White American name?

Now let's compute WEAT statistic over all group of Black American and White American names with pos / neg attributes:
"""

compute_test_statistic(embedding_dict['Black_American'], embedding_dict['White_American'], 
                       embedding_dict['negative'], embedding_dict['positive'])

"""Let's do the same for Japanese and Korean names:"""

## FILL IN THE CODE HERE ##
compute_test_statistic(embedding_dict['Korean_names'], embedding_dict['Japanese_names'], 
                       embedding_dict['negative'], embedding_dict['positive'])

"""Question 11: what WEAT statistic do you observe for different groups of names? What does it indicate? (write a brief description)

It indicates the bias in word embeddings toward the Korean names vs Japanese names is less than when we consider this statistic towards Black American vs White American.

Congratulations! You have finished the first assignment :) Please upload your completed ipynb notebook to your github.
"""

